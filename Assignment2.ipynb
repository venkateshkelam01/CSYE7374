{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5978984d",
   "metadata": {},
   "source": [
    "# Assignment 2 — Mini GPT (Decoder-only Transformer)\n",
    "\n",
    "This notebook trains a **small transformer language model** from scratch for **next-token prediction**.\n",
    "\n",
    "## What you need\n",
    "- A 1D NumPy array of token IDs from Assignment 1 at `data/tokenized/corpus_ids.npy` (edit the path below if different).\n",
    "- Or set `use_synthetic = True` to do a quick smoke test without real data.\n",
    "\n",
    "## Deliverables you'll get here\n",
    "- Model implementation (1–2 layers, 2–4 heads, 64–256 hidden size)\n",
    "- Training loop with **cross-entropy** and **perplexity** logging\n",
    "- **Checkpoints** saved under `runs/mini_gpt/`\n",
    "- **Loss** and **Perplexity** plots saved to the same folder\n",
    "\n",
    "**Tip:** Start with small sizes if you're on CPU (e.g., `d_model=64`, `n_layers=1`, `block_size=32`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150d4505-1187-40a5-b553-a8de0da446f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level type: <class 'dict'>\n",
      "Keys: dict_keys(['input_ids', 'attention_mask'])\n",
      "Using key: input_ids\n",
      "Saved: data/tokenized/corpus_ids.npy | tokens: 104871936\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, pathlib\n",
    "\n",
    "inp = \"data/tokenized/tokenized_blocks.pt\"\n",
    "out = \"data/tokenized/corpus_ids.npy\"\n",
    "\n",
    "obj = torch.load(inp, map_location=\"cpu\")\n",
    "print(\"Top-level type:\", type(obj))\n",
    "if isinstance(obj, dict):\n",
    "    print(\"Keys:\", obj.keys())\n",
    "\n",
    "# Try common keys\n",
    "if isinstance(obj, dict):\n",
    "    for k in [\"ids\", \"input_ids\", \"token_ids\", \"data\"]:\n",
    "        if k in obj:\n",
    "            obj = obj[k]\n",
    "            print(\"Using key:\", k)\n",
    "            break\n",
    "\n",
    "if torch.is_tensor(obj):\n",
    "    ids = obj.detach().cpu().numpy()\n",
    "else:\n",
    "    ids = np.array(obj)\n",
    "\n",
    "ids = ids.astype(np.int64).reshape(-1)\n",
    "pathlib.Path(\"data/tokenized\").mkdir(parents=True, exist_ok=True)\n",
    "np.save(out, ids)\n",
    "print(\"Saved:\", out, \"| tokens:\", len(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34df56c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded. Edit as needed and run the next cells ↓\n"
     ]
    }
   ],
   "source": [
    "use_synthetic = False          # True to generate random tokens for a smoke test\n",
    "data_path = 'data/tokenized/corpus_ids.npy'  # Path to your 1D numpy array of token ids\n",
    "vocab_size = 50257              # Must match your tokenizer\n",
    "min_tokens = 200_000            # Synthetic-only: how many random tokens to create\n",
    "\n",
    "block_size = 128                # 32–128\n",
    "d_model = 256                   # 64–256\n",
    "n_heads = 4                     # 2–4\n",
    "n_layers = 2                    # 1–2\n",
    "d_ff = 0                        # 0 => 4 * d_model\n",
    "dropout = 0.0\n",
    "tie_weights = True\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "lr = 1e-3\n",
    "weight_decay = 0.01\n",
    "grad_clip = 1.0\n",
    "val_frac = 0.1\n",
    "log_every = 200\n",
    "ckpt_every = 1000\n",
    "out_dir = 'runs/mini_gpt'\n",
    "\n",
    "print('Config loaded. Edit as needed and run the next cells ↓')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6679c1-704d-44d3-8851-2b34c75796ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb3d5ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a091f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenBlockDataset(Dataset):\n",
    "    def __init__(self, ids: np.ndarray, block_size: int):\n",
    "        assert ids.ndim == 1, 'Expected 1D array of token ids'\n",
    "        self.ids = torch.from_numpy(ids.astype(np.int64))\n",
    "        self.block_size = block_size\n",
    "        self.max_start = len(self.ids) - (block_size + 1)\n",
    "        assert self.max_start > 0, 'Not enough tokens for this block_size'\n",
    "    def __len__(self):\n",
    "        return self.max_start\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.ids[idx:idx + self.block_size]\n",
    "        y = self.ids[idx + 1:idx + 1 + self.block_size]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f178689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    vocab_size: int\n",
    "    block_size: int = 128\n",
    "    d_model: int = 256\n",
    "    n_heads: int = 4\n",
    "    n_layers: int = 2\n",
    "    d_ff: Optional[int] = None\n",
    "    dropout: float = 0.0\n",
    "    tie_weights: bool = True\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout, block_size):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, 'd_model must be divisible by n_heads'\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(d_model, 3 * d_model, bias=False)\n",
    "        self.out = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.resid_drop = nn.Dropout(dropout)\n",
    "        mask = torch.tril(torch.ones(block_size, block_size)).view(1, 1, block_size, block_size)\n",
    "        self.register_buffer('mask', mask)\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.split(C, dim=2)\n",
    "        q = q.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        att = torch.softmax(att, dim=-1)\n",
    "        att = self.attn_drop(att)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_drop(self.out(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130ebe03-f863-4d7a-a100-20a14962001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        inner = d_ff if d_ff is not None else 4 * d_model\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, inner),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(inner, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout, block_size, d_ff):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.attn = CausalSelfAttention(d_model, n_heads, dropout, block_size)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.tok_emb = nn.Embedding(cfg.vocab_size, cfg.d_model)\n",
    "        self.pos_emb = nn.Embedding(cfg.block_size, cfg.d_model)\n",
    "        self.drop = nn.Dropout(cfg.dropout)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg.d_model, cfg.n_heads, cfg.dropout, cfg.block_size, cfg.d_ff)\n",
    "            for _ in range(cfg.n_layers)\n",
    "        ])\n",
    "        self.ln_f = nn.LayerNorm(cfg.d_model)\n",
    "        self.head = nn.Linear(cfg.d_model, cfg.vocab_size, bias=False)\n",
    "        if cfg.tie_weights:\n",
    "            self.head.weight = self.tok_emb.weight\n",
    "        self.apply(self._init_weights)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.cfg.block_size, 'Sequence length exceeds block_size'\n",
    "        tok = self.tok_emb(idx)\n",
    "        pos = self.pos_emb(torch.arange(T, device=idx.device))\n",
    "        x = self.drop(tok + pos)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5691778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(loss_value: float) -> float:\n",
    "    return float(math.exp(loss_value))\n",
    "\n",
    "def load_ids(path: Path, synthetic: bool, vocab_size: int, min_tokens: int = 200_000):\n",
    "    if synthetic:\n",
    "        rng = np.random.default_rng(0)\n",
    "        size = max(min_tokens, 200_000)\n",
    "        print(f'[synthetic] Generating {size:,} random tokens with vocab_size={vocab_size} ...')\n",
    "        return rng.integers(0, vocab_size, size=size, dtype=np.int64)\n",
    "    else:\n",
    "        assert path.exists(), f'Token id file not found: {path}'\n",
    "        print(f'Loading token ids from: {path}')\n",
    "        arr = np.load(path)\n",
    "        if arr.ndim > 1:\n",
    "            arr = arr.reshape(-1)\n",
    "        return arr.astype(np.int64)\n",
    "\n",
    "def plot_curves(out_dir: Path, history):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    steps = [h['step'] for h in history]\n",
    "    losses = [h['loss'] for h in history]\n",
    "    ppls = [h['perplexity'] for h in history]\n",
    "    plt.figure()\n",
    "    plt.plot(steps, losses)\n",
    "    plt.xlabel('Step'); plt.ylabel('Loss'); plt.title('Training Loss'); plt.tight_layout()\n",
    "    plt.savefig(out_dir / 'loss_curve.png', dpi=150)\n",
    "    plt.figure()\n",
    "    plt.plot(steps, ppls)\n",
    "    plt.xlabel('Step'); plt.ylabel('Perplexity'); plt.title('Training Perplexity'); plt.tight_layout()\n",
    "    plt.savefig(out_dir / 'perplexity_curve.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289e051",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[synthetic] Generating 200,000 random tokens with vocab_size=50257 ...\n"
     ]
    }
   ],
   "source": [
    "def train_loop():\n",
    "    cfg = GPTConfig(\n",
    "        vocab_size=vocab_size, block_size=block_size, d_model=d_model,\n",
    "        n_heads=n_heads, n_layers=n_layers, d_ff=(None if d_ff<=0 else d_ff),\n",
    "        dropout=dropout, tie_weights=tie_weights\n",
    "    )\n",
    "    print('Using device:', device)\n",
    "    ids = load_ids(Path(data_path), synthetic=use_synthetic, vocab_size=vocab_size, min_tokens=min_tokens)\n",
    "    n = len(ids)\n",
    "    split = int(n * (1.0 - val_frac))\n",
    "    train_ids = ids[:split]\n",
    "    val_ids = ids[split:] if split < n else ids[:int(0.1*n)]\n",
    "    train_ds = TokenBlockDataset(train_ids, block_size)\n",
    "    val_ds = TokenBlockDataset(val_ids, block_size)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    model = MiniGPT(cfg).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.95), weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = []\n",
    "    step = 0\n",
    "    def run_eval():\n",
    "        model.eval()\n",
    "        total_loss, total_tokens = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = x.to(device); y = y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                total_loss += loss.item() * x.numel()\n",
    "                total_tokens += x.numel()\n",
    "        avg = total_loss / max(total_tokens, 1)\n",
    "        return avg, perplexity(avg)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device); y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            if step % log_every == 0:\n",
    "                val_loss, val_ppl = run_eval()\n",
    "                history.append({'step': step, 'loss': val_loss, 'perplexity': val_ppl})\n",
    "                print(f'[step {step:6d}] val loss={val_loss:.4f} | val ppl={val_ppl:.2f}')\n",
    "            if ckpt_every > 0 and step % ckpt_every == 0 and step > 0:\n",
    "                Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "                torch.save({'model_state': model.state_dict()}, Path(out_dir)/f'mini_gpt_step_{step}.pt')\n",
    "            step += 1\n",
    "        val_loss, val_ppl = run_eval()\n",
    "        history.append({'step': step, 'loss': val_loss, 'perplexity': val_ppl})\n",
    "        print(f'[EPOCH {epoch+1}/{epochs}] val loss={val_loss:.4f} | val ppl={val_ppl:.2f}')\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'model_state': model.state_dict()}, Path(out_dir)/f'mini_gpt_epoch_{epoch+1}.pt')\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save({'model_state': model.state_dict()}, Path(out_dir)/'mini_gpt_checkpoint.pt')\n",
    "    print('Saved final checkpoint to', Path(out_dir)/'mini_gpt_checkpoint.pt')\n",
    "    plot_curves(Path(out_dir), history)\n",
    "    print('Saved loss_curve.png and perplexity_curve.png to', out_dir)\n",
    "train_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e39476",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Re-run with different hyperparameters and compare perplexities.\n",
    "- Include the loss/perplexity plots in your report.\n",
    "- Submit `runs/mini_gpt/mini_gpt_checkpoint.pt` as your final checkpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
